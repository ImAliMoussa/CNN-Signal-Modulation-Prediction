Dataset consists of signals modulated using 10 different modulation types. Dataset is around 1,200,000 examples. There are 20 different SNR values from -20 to 18 with steps 2 [-20, -18, ...18]. So 1,200,200 / 20 = 60,000 examples for each SNR value. There are 10 different modulation types, so 60,000 / 10 = 6,000 signals for each modulation types per SNR value. 

You'll find a notebook containing different approaches used to predict modulation types, such as a logistic regression unit, a decision tree, random forest and a simple neural network and lastly the CNN model. Logistic regression and decision tree gave bad results, around 20% accuracy. Neural network gave around 60% accuracy, could probably give better results if you increase number of layers of neural network. Random forest gave about the same results as well. CNN model gave the best results, best result was at SNR = 0 where it gave test accuracy of around 89%. There's also a python notebook which we used for hyperparameter tuning using tensorflow and tensorboard of activation function, dropout rate and whether to use batch normalization. Other thing you could tune: find a better dropout rate in the range 0.3 -> 0.5, try out different optimizers (I used Adam and RMSPROP and found they gave around the same results), try out different learning rates.
